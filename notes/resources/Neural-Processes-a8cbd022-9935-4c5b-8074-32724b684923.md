# Neural Processes

Status: Processed
Subtask: i) ts-learning,iv) global-local

[https://kasparmartens.rbind.io/post/np/](https://kasparmartens.rbind.io/post/np/)

[https://chrisorm.github.io/NGP.html](https://chrisorm.github.io/NGP.html)

![](Untitled-308c579f-385e-4a38-8126-7b5abb0b4dc4.png)

![](Untitled-75ff8697-2cdc-494f-9f8b-ce15c86aee47.png)

- These can be used for the "global-local" learning task:

    ![](Untitled-b2a13706-b76b-4440-8e57-c435d93046d1.png)

    - "The latent z can be seen as a way to share information across different data sets"
    - It can be trained using a very diverse context set, and then a more tailored context set can be given at test time
        - example in waipoua: train with all the transformers, and at prediction use each transformer's measurements only

![](Untitled-8567ec44-5fe3-44ae-9bbd-fa9a32b5bf0f.png)

![](Untitled-02b699ce-a8e4-4e38-8219-1be4240b0ae3.png)

- Drawbacks:
    - prior is uninterpretable
        - it is set by defining the architectures of h and g
    - very initialization dependent